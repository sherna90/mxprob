{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, data_home='../data',cache=True,as_frame=False)\n",
    "X=X/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples,D=X_train.shape\n",
    "num_outputs=len(np.unique(y_train))\n",
    "\n",
    "model_ctx=mx.gpu()\n",
    "net = gluon.nn.Dense(num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().initialize(mx.init.Normal(sigma=1.), ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batchsize,ctx):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    for start_idx in range(0, X.shape[0] - batchsize + 1, batchsize):\n",
    "        excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield nd.array(X[excerpt],ctx=ctx), nd.array(y[excerpt],ctx=ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net,X,y,batch_size,ctx):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for data,label in iterate_minibatches(X,y,batch_size,ctx):\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "    return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 2.542672055943736, Train_acc 0.8008170871559633, Test_acc 0.8016071428571429\n",
      "Epoch 1. Loss: 1.0615867886330401, Train_acc 0.8419581422018348, Test_acc 0.8411964285714286\n",
      "Epoch 2. Loss: 0.8728184244201652, Train_acc 0.857368119266055, Test_acc 0.8571785714285715\n",
      "Epoch 3. Loss: 0.774513258108603, Train_acc 0.8672591743119266, Test_acc 0.8669464285714286\n",
      "Epoch 4. Loss: 0.7108107527095292, Train_acc 0.8734948394495413, Test_acc 0.8737857142857143\n",
      "Epoch 5. Loss: 0.664924758946257, Train_acc 0.8777952981651376, Test_acc 0.8785535714285714\n",
      "Epoch 6. Loss: 0.629691659716091, Train_acc 0.8823824541284404, Test_acc 0.8823928571428571\n",
      "Epoch 7. Loss: 0.6014451960735023, Train_acc 0.8843893348623854, Test_acc 0.88525\n",
      "Epoch 8. Loss: 0.5780878436389778, Train_acc 0.8872563073394495, Test_acc 0.8880892857142857\n",
      "Epoch 9. Loss: 0.558328430362578, Train_acc 0.8901232798165137, Test_acc 0.8901071428571429\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "moving_loss = 0.\n",
    "batch_size=64\n",
    "for e in range(epochs):\n",
    "    cumulative_loss = 0\n",
    "    for data,label in iterate_minibatches(X,y,batch_size,model_ctx):\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        cumulative_loss += nd.sum(loss).asscalar()\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(net,X_train,y_train,batch_size,model_ctx)\n",
    "    train_accuracy = evaluate_accuracy(net,X_test,y_test,batch_size,model_ctx)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, cumulative_loss/num_examples, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense2_weight\n",
      "dense2_bias\n"
     ]
    }
   ],
   "source": [
    "for par in net.params:\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=net(nd.array(X_test,ctx=model_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1367\n",
      "           1       0.95      0.98      0.96      1579\n",
      "           2       0.89      0.91      0.90      1396\n",
      "           3       0.87      0.91      0.89      1448\n",
      "           4       0.93      0.91      0.92      1346\n",
      "           5       0.89      0.86      0.88      1273\n",
      "           6       0.96      0.95      0.95      1416\n",
      "           7       0.93      0.93      0.93      1483\n",
      "           8       0.90      0.83      0.87      1303\n",
      "           9       0.87      0.91      0.89      1389\n",
      "\n",
      "    accuracy                           0.92     14000\n",
      "   macro avg       0.92      0.91      0.91     14000\n",
      "weighted avg       0.92      0.92      0.92     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.int32(y_test), y_pred.argmax(axis=1).asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
