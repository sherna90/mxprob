{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solid-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulation-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "plastic-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-signal",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "leading-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import ndarray as nd\n",
    "from hamiltonian.inference.sgd import sgd\n",
    "from hamiltonian.models.softmax import softmax\n",
    "\n",
    "model_ctx=mx.cpu()\n",
    "hyper={'alpha':1}\n",
    "in_units=[X.shape[1],1]\n",
    "out_units=len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "approximate-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=softmax(hyper,in_units,out_units,ctx=model_ctx)\n",
    "inference=sgd(model,model.par,step_size=0.01,ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numerical-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 112.47it/s]\n"
     ]
    }
   ],
   "source": [
    "par,loss=inference.fit(epochs=1000,batch_size=60,gamma=0.9,\n",
    "                       X_train=nd.array(X_train,ctx=model_ctx),y_train=nd.array(y_train,ctx=model_ctx),verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hollywood-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules re-loaded\n"
     ]
    }
   ],
   "source": [
    "import hamiltonian\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    importlib.reload(hamiltonian.models.softmax)\n",
    "    importlib.reload(hamiltonian.inference.sgd)\n",
    "    print('modules re-loaded')\n",
    "except:\n",
    "    print('no modules loaded yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lonely-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.weight': Parameter (shape=(3, 4), dtype=float32),\n",
       " '1.bias': Parameter (shape=(3,), dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flush-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(model.par,nd.array(X_test,ctx=model_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chinese-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       0.57      0.80      0.67         5\n",
      "           2       1.00      0.79      0.88        14\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.83      0.86      0.83        30\n",
      "weighted avg       0.90      0.87      0.87        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.int32(y_test),np.int32(y_pred.sample().asnumpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-reference",
   "metadata": {},
   "source": [
    "# Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "silent-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ctx=mx.cpu()\n",
    "hyper={'alpha':25.}\n",
    "in_units=[X.shape[1],1]\n",
    "out_units=len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accompanied-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonian.inference.hmc import hmc\n",
    "from hamiltonian.models.softmax import softmax\n",
    "\n",
    "model=softmax(hyper,in_units,out_units,ctx=model_ctx)\n",
    "inference=hmc(model,model.par,step_size=0.1,ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "valid-observation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules re-loaded\n"
     ]
    }
   ],
   "source": [
    "import hamiltonian\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    importlib.reload(hamiltonian.models.softmax)\n",
    "    importlib.reload(hamiltonian.inference.hmc)\n",
    "    print('modules re-loaded')\n",
    "except:\n",
    "    print('no modules loaded yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "difficult-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [05:56<00:00, 11.21it/s]\n",
      "100%|██████████| 4000/4000 [05:49<00:00, 11.45it/s]\n",
      "100%|██████████| 4000/4000 [05:44<00:00, 11.60it/s]\n",
      "100%|██████████| 4000/4000 [05:45<00:00, 11.57it/s]\n"
     ]
    }
   ],
   "source": [
    "samples=inference.sample(epochs=3000,burn_in=1000,path_length=10.0,chains=4,X_train=nd.array(X_train,ctx=model_ctx),y_train=nd.array(y_train,ctx=model_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "integral-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "geographic-victim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2999, 3, 4)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]['1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "forbidden-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "datasets=[az.convert_to_inference_data(sample) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "legislative-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = az.concat(datasets, dim=\"chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "increased-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.weight[0,0]</th>\n",
       "      <td>-87.499</td>\n",
       "      <td>74.573</td>\n",
       "      <td>-201.976</td>\n",
       "      <td>-10.587</td>\n",
       "      <td>36.768</td>\n",
       "      <td>28.104</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[0,1]</th>\n",
       "      <td>-1.314</td>\n",
       "      <td>64.932</td>\n",
       "      <td>-100.949</td>\n",
       "      <td>84.888</td>\n",
       "      <td>31.938</td>\n",
       "      <td>24.402</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[0,2]</th>\n",
       "      <td>-5.574</td>\n",
       "      <td>51.361</td>\n",
       "      <td>-70.875</td>\n",
       "      <td>74.838</td>\n",
       "      <td>25.036</td>\n",
       "      <td>19.099</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[0,3]</th>\n",
       "      <td>-54.049</td>\n",
       "      <td>101.399</td>\n",
       "      <td>-138.983</td>\n",
       "      <td>144.311</td>\n",
       "      <td>50.234</td>\n",
       "      <td>38.429</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,0]</th>\n",
       "      <td>29.270</td>\n",
       "      <td>71.390</td>\n",
       "      <td>-84.487</td>\n",
       "      <td>93.299</td>\n",
       "      <td>34.901</td>\n",
       "      <td>26.638</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,1]</th>\n",
       "      <td>40.095</td>\n",
       "      <td>30.206</td>\n",
       "      <td>8.669</td>\n",
       "      <td>80.464</td>\n",
       "      <td>14.482</td>\n",
       "      <td>11.018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,2]</th>\n",
       "      <td>-14.001</td>\n",
       "      <td>15.572</td>\n",
       "      <td>-36.892</td>\n",
       "      <td>17.055</td>\n",
       "      <td>5.927</td>\n",
       "      <td>4.382</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,3]</th>\n",
       "      <td>-23.361</td>\n",
       "      <td>88.306</td>\n",
       "      <td>-110.986</td>\n",
       "      <td>104.973</td>\n",
       "      <td>43.588</td>\n",
       "      <td>33.323</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,0]</th>\n",
       "      <td>-22.744</td>\n",
       "      <td>81.296</td>\n",
       "      <td>-116.644</td>\n",
       "      <td>65.272</td>\n",
       "      <td>40.439</td>\n",
       "      <td>30.958</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,1]</th>\n",
       "      <td>-15.473</td>\n",
       "      <td>112.401</td>\n",
       "      <td>-189.414</td>\n",
       "      <td>125.882</td>\n",
       "      <td>55.908</td>\n",
       "      <td>42.799</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,2]</th>\n",
       "      <td>27.504</td>\n",
       "      <td>47.152</td>\n",
       "      <td>-10.355</td>\n",
       "      <td>96.833</td>\n",
       "      <td>21.656</td>\n",
       "      <td>16.369</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,3]</th>\n",
       "      <td>19.498</td>\n",
       "      <td>43.845</td>\n",
       "      <td>-34.192</td>\n",
       "      <td>74.461</td>\n",
       "      <td>20.956</td>\n",
       "      <td>15.935</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.bias[0]</th>\n",
       "      <td>-92.306</td>\n",
       "      <td>59.600</td>\n",
       "      <td>-156.266</td>\n",
       "      <td>1.368</td>\n",
       "      <td>29.186</td>\n",
       "      <td>22.283</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.bias[1]</th>\n",
       "      <td>-18.612</td>\n",
       "      <td>45.013</td>\n",
       "      <td>-87.893</td>\n",
       "      <td>30.328</td>\n",
       "      <td>21.611</td>\n",
       "      <td>16.446</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.bias[2]</th>\n",
       "      <td>18.200</td>\n",
       "      <td>40.812</td>\n",
       "      <td>-34.779</td>\n",
       "      <td>100.823</td>\n",
       "      <td>19.315</td>\n",
       "      <td>14.665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean       sd   hdi_3%  hdi_97%  mcse_mean  mcse_sd  \\\n",
       "1.weight[0,0] -87.499   74.573 -201.976  -10.587     36.768   28.104   \n",
       "1.weight[0,1]  -1.314   64.932 -100.949   84.888     31.938   24.402   \n",
       "1.weight[0,2]  -5.574   51.361  -70.875   74.838     25.036   19.099   \n",
       "1.weight[0,3] -54.049  101.399 -138.983  144.311     50.234   38.429   \n",
       "1.weight[1,0]  29.270   71.390  -84.487   93.299     34.901   26.638   \n",
       "1.weight[1,1]  40.095   30.206    8.669   80.464     14.482   11.018   \n",
       "1.weight[1,2] -14.001   15.572  -36.892   17.055      5.927    4.382   \n",
       "1.weight[1,3] -23.361   88.306 -110.986  104.973     43.588   33.323   \n",
       "1.weight[2,0] -22.744   81.296 -116.644   65.272     40.439   30.958   \n",
       "1.weight[2,1] -15.473  112.401 -189.414  125.882     55.908   42.799   \n",
       "1.weight[2,2]  27.504   47.152  -10.355   96.833     21.656   16.369   \n",
       "1.weight[2,3]  19.498   43.845  -34.192   74.461     20.956   15.935   \n",
       "1.bias[0]     -92.306   59.600 -156.266    1.368     29.186   22.283   \n",
       "1.bias[1]     -18.612   45.013  -87.893   30.328     21.611   16.446   \n",
       "1.bias[2]      18.200   40.812  -34.779  100.823     19.315   14.665   \n",
       "\n",
       "               ess_bulk  ess_tail  r_hat  \n",
       "1.weight[0,0]       4.0       4.0   3.57  \n",
       "1.weight[0,1]       4.0       5.0   3.87  \n",
       "1.weight[0,2]       5.0      36.0   3.26  \n",
       "1.weight[0,3]       4.0       5.0   3.18  \n",
       "1.weight[1,0]       5.0       4.0   3.93  \n",
       "1.weight[1,1]       5.0       4.0   2.95  \n",
       "1.weight[1,2]       6.0      17.0   1.76  \n",
       "1.weight[1,3]       5.0       5.0   2.89  \n",
       "1.weight[2,0]       5.0       7.0   2.55  \n",
       "1.weight[2,1]       4.0       5.0   5.46  \n",
       "1.weight[2,2]       5.0      14.0   2.44  \n",
       "1.weight[2,3]       5.0       4.0   2.42  \n",
       "1.bias[0]           5.0       7.0   2.57  \n",
       "1.bias[1]           5.0      11.0   2.90  \n",
       "1.bias[2]           5.0       4.0   2.67  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-peoples",
   "metadata": {},
   "source": [
    "# PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "knowing-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sitting-springer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:56<00:00 Sampling 4 chains, 660 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 118 seconds.\n",
      "There were 602 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6508177192963824, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 47 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 9 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=5, shape=3)\n",
    "    beta = pm.Normal('beta', mu=0, sd=5, shape=(4,3))\n",
    "    mu = pm.Deterministic('mu', alpha + pm.math.dot(X_train, beta))\n",
    "    theta = tt.nnet.softmax(mu)\n",
    "    y_hat = pm.Categorical('y_hat', p=theta, observed=y_train)\n",
    "    trace_s = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "removable-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>1.484</td>\n",
       "      <td>4.946</td>\n",
       "      <td>-7.465</td>\n",
       "      <td>11.088</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.216</td>\n",
       "      <td>271.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>4.740</td>\n",
       "      <td>4.069</td>\n",
       "      <td>-2.664</td>\n",
       "      <td>12.532</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>3535.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>-5.735</td>\n",
       "      <td>4.039</td>\n",
       "      <td>-13.106</td>\n",
       "      <td>1.890</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0,0]</th>\n",
       "      <td>2.081</td>\n",
       "      <td>3.814</td>\n",
       "      <td>-5.077</td>\n",
       "      <td>9.388</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.189</td>\n",
       "      <td>284.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0,1]</th>\n",
       "      <td>0.737</td>\n",
       "      <td>3.065</td>\n",
       "      <td>-5.310</td>\n",
       "      <td>6.164</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.145</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0,2]</th>\n",
       "      <td>-2.494</td>\n",
       "      <td>3.130</td>\n",
       "      <td>-8.463</td>\n",
       "      <td>3.391</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.106</td>\n",
       "      <td>429.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1,0]</th>\n",
       "      <td>4.587</td>\n",
       "      <td>4.170</td>\n",
       "      <td>-3.104</td>\n",
       "      <td>11.967</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.334</td>\n",
       "      <td>83.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1,1]</th>\n",
       "      <td>-0.686</td>\n",
       "      <td>3.510</td>\n",
       "      <td>-7.020</td>\n",
       "      <td>5.947</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.263</td>\n",
       "      <td>100.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1,2]</th>\n",
       "      <td>-4.631</td>\n",
       "      <td>3.568</td>\n",
       "      <td>-10.536</td>\n",
       "      <td>2.429</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.246</td>\n",
       "      <td>109.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2,0]</th>\n",
       "      <td>-6.797</td>\n",
       "      <td>3.746</td>\n",
       "      <td>-13.680</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.126</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2,1]</th>\n",
       "      <td>0.496</td>\n",
       "      <td>3.257</td>\n",
       "      <td>-5.141</td>\n",
       "      <td>6.788</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.127</td>\n",
       "      <td>333.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2,2]</th>\n",
       "      <td>5.999</td>\n",
       "      <td>3.378</td>\n",
       "      <td>0.267</td>\n",
       "      <td>12.497</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.169</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3,0]</th>\n",
       "      <td>-3.704</td>\n",
       "      <td>4.827</td>\n",
       "      <td>-12.716</td>\n",
       "      <td>4.819</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.195</td>\n",
       "      <td>335.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3,1]</th>\n",
       "      <td>-2.854</td>\n",
       "      <td>3.504</td>\n",
       "      <td>-9.589</td>\n",
       "      <td>3.670</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.107</td>\n",
       "      <td>852.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3,2]</th>\n",
       "      <td>5.974</td>\n",
       "      <td>3.597</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>12.927</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.170</td>\n",
       "      <td>468.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   1.484  4.946  -7.465   11.088      0.305    0.216     271.0   \n",
       "alpha[1]   4.740  4.069  -2.664   12.532      0.098    0.074    1735.0   \n",
       "alpha[2]  -5.735  4.039 -13.106    1.890      0.106    0.075    1483.0   \n",
       "beta[0,0]  2.081  3.814  -5.077    9.388      0.231    0.189     284.0   \n",
       "beta[0,1]  0.737  3.065  -5.310    6.164      0.205    0.145     242.0   \n",
       "beta[0,2] -2.494  3.130  -8.463    3.391      0.150    0.106     429.0   \n",
       "beta[1,0]  4.587  4.170  -3.104   11.967      0.471    0.334      83.0   \n",
       "beta[1,1] -0.686  3.510  -7.020    5.947      0.370    0.263     100.0   \n",
       "beta[1,2] -4.631  3.568 -10.536    2.429      0.348    0.246     109.0   \n",
       "beta[2,0] -6.797  3.746 -13.680    0.135      0.178    0.126     434.0   \n",
       "beta[2,1]  0.496  3.257  -5.141    6.788      0.180    0.127     333.0   \n",
       "beta[2,2]  5.999  3.378   0.267   12.497      0.239    0.169     211.0   \n",
       "beta[3,0] -3.704  4.827 -12.716    4.819      0.269    0.195     335.0   \n",
       "beta[3,1] -2.854  3.504  -9.589    3.670      0.120    0.107     852.0   \n",
       "beta[3,2]  5.974  3.597  -0.469   12.927      0.171    0.170     468.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]      558.0   1.02  \n",
       "alpha[1]     3535.0   1.01  \n",
       "alpha[2]     2556.0   1.04  \n",
       "beta[0,0]     201.0   1.02  \n",
       "beta[0,1]    1375.0   1.03  \n",
       "beta[0,2]     810.0   1.02  \n",
       "beta[1,0]     285.0   1.05  \n",
       "beta[1,1]     213.0   1.04  \n",
       "beta[1,2]     764.0   1.03  \n",
       "beta[2,0]    1978.0   1.02  \n",
       "beta[2,1]     660.0   1.03  \n",
       "beta[2,2]    1697.0   1.03  \n",
       "beta[3,0]     502.0   1.02  \n",
       "beta[3,1]    1034.0   1.01  \n",
       "beta[3,2]    3270.0   1.02  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace_s,var_names=[\"alpha\", \"beta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "purple-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loo=az.loo(trace_s,pointwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "passing-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.455271778875396"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loo.loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "racial-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo=data_loo.loo_i.data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "nonprofit-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_hat=data_loo.pareto_k.data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "induced-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean f-1 : 0.9725425069936648, std f-1 : 0.02303430770368892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "score=[]\n",
    "for i in range(trace_s['mu'].shape[0]):\n",
    "    y_pred=trace_s['mu'][i,:,:].argmax(axis=1)\n",
    "    score.append(f1_score(np.int32(y_train),np.int32(y_pred), average='macro'))\n",
    "print('mean f-1 : {0}, std f-1 : {1}'.format(np.mean(score),2*np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "judicial-burst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:32<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_samples = pm.sample_posterior_predictive(trace_s,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "accepted-fusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean f-1 : 0.9619404455625193, std f-1 : 0.04712176330932348\n"
     ]
    }
   ],
   "source": [
    "score=[]\n",
    "for q in np.arange(.1,.9,.1):\n",
    "    y_hat=np.quantile(total_samples['y_hat'],q,axis=0)\n",
    "    score.append(f1_score(np.int32(y_train),np.int32(y_hat),average='macro'))\n",
    "print('mean f-1 : {0}, std f-1 : {1}'.format(np.mean(score),2*np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "complete-portal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean f-1 : 0.9477073784348193, std f-1 : 0.07247340108374999\n"
     ]
    }
   ],
   "source": [
    "score=[]\n",
    "for q in np.arange(.1,.9,.1):\n",
    "    y_hat=np.quantile(total_samples['y_hat'],q,axis=0)\n",
    "    score.append(f1_score(np.int32(y_train),np.int32(y_hat),sample_weight=1.-np.clip(k_hat,0,1),average='weighted'))\n",
    "print('mean f-1 : {0}, std f-1 : {1}'.format(np.mean(score),2*np.std(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-brave",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
