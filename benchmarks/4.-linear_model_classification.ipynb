{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import ndarray as nd\n",
    "from hamiltonian.inference.sgd import sgd\n",
    "from hamiltonian.models.softmax import softmax\n",
    "\n",
    "model_ctx=mx.cpu()\n",
    "hyper={'alpha':1}\n",
    "in_units=[X.shape[1],1]\n",
    "out_units=len(np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=softmax(hyper,in_units,out_units,ctx=model_ctx)\n",
    "inference=sgd(model,model.par,step_size=0.01,ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 133.93it/s]\n"
     ]
    }
   ],
   "source": [
    "par,loss=inference.fit(epochs=1000,batch_size=60,gamma=0.9,\n",
    "                       X_train=nd.array(X_train,ctx=model_ctx),y_train=nd.array(y_train,ctx=model_ctx),verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules re-loaded\n"
     ]
    }
   ],
   "source": [
    "import hamiltonian\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    importlib.reload(hamiltonian.models.softmax)\n",
    "    importlib.reload(hamiltonian.inference.sgd)\n",
    "    print('modules re-loaded')\n",
    "except:\n",
    "    print('no modules loaded yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.weight': Parameter (shape=(3, 4), dtype=float32),\n",
       " '1.bias': Parameter (shape=(3,), dtype=float32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(model.par,nd.array(X_test,ctx=model_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.83      0.91      0.87        11\n",
      "           2       0.90      0.82      0.86        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.91      0.91        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.int32(y_test),np.int32(y_pred.sample().asnumpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ctx=mx.cpu()\n",
    "hyper={'alpha':25.}\n",
    "in_units=[X.shape[1],1]\n",
    "out_units=len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonian.inference.hmc import hmc\n",
    "from hamiltonian.models.softmax import softmax\n",
    "\n",
    "model=softmax(hyper,in_units,out_units,ctx=model_ctx)\n",
    "inference=hmc(model,model.par,step_size=0.1,ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules re-loaded\n"
     ]
    }
   ],
   "source": [
    "import hamiltonian\n",
    "import importlib\n",
    "\n",
    "try:\n",
    "    importlib.reload(hamiltonian.models.softmax)\n",
    "    importlib.reload(hamiltonian.inference.hmc)\n",
    "    print('modules re-loaded')\n",
    "except:\n",
    "    print('no modules loaded yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [01:48<00:00, 36.99it/s]\n",
      "100%|██████████| 4000/4000 [01:47<00:00, 37.17it/s]\n",
      "100%|██████████| 4000/4000 [01:46<00:00, 37.59it/s]\n",
      "100%|██████████| 4000/4000 [01:48<00:00, 36.86it/s]\n"
     ]
    }
   ],
   "source": [
    "samples=inference.sample(epochs=3000,burn_in=1000,path_length=1.0,chains=4,X_train=nd.array(X_train,ctx=model_ctx),y_train=nd.array(y_train,ctx=model_ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "datasets=[az.convert_to_inference_data(sample) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = az.concat(datasets, dim=\"chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.weight[0,0]</th>\n",
       "      <td>-7.056</td>\n",
       "      <td>20.094</td>\n",
       "      <td>-34.199</td>\n",
       "      <td>22.528</td>\n",
       "      <td>10.037</td>\n",
       "      <td>7.689</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.128774e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[0,1]</th>\n",
       "      <td>19.531</td>\n",
       "      <td>16.355</td>\n",
       "      <td>2.257</td>\n",
       "      <td>44.474</td>\n",
       "      <td>8.169</td>\n",
       "      <td>6.258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[0,2]</th>\n",
       "      <td>-53.708</td>\n",
       "      <td>23.179</td>\n",
       "      <td>-82.892</td>\n",
       "      <td>-18.169</td>\n",
       "      <td>11.578</td>\n",
       "      <td>8.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.128774e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[0,3]</th>\n",
       "      <td>-23.018</td>\n",
       "      <td>9.620</td>\n",
       "      <td>-33.999</td>\n",
       "      <td>-7.621</td>\n",
       "      <td>4.805</td>\n",
       "      <td>3.681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,0]</th>\n",
       "      <td>6.788</td>\n",
       "      <td>8.489</td>\n",
       "      <td>-6.878</td>\n",
       "      <td>15.597</td>\n",
       "      <td>4.240</td>\n",
       "      <td>3.248</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,1]</th>\n",
       "      <td>-8.613</td>\n",
       "      <td>10.146</td>\n",
       "      <td>-23.316</td>\n",
       "      <td>5.273</td>\n",
       "      <td>5.068</td>\n",
       "      <td>3.883</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,2]</th>\n",
       "      <td>19.112</td>\n",
       "      <td>3.539</td>\n",
       "      <td>14.182</td>\n",
       "      <td>22.795</td>\n",
       "      <td>1.768</td>\n",
       "      <td>1.354</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.128774e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[1,3]</th>\n",
       "      <td>5.788</td>\n",
       "      <td>1.740</td>\n",
       "      <td>3.502</td>\n",
       "      <td>8.400</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.666</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,0]</th>\n",
       "      <td>0.454</td>\n",
       "      <td>17.906</td>\n",
       "      <td>-18.488</td>\n",
       "      <td>29.164</td>\n",
       "      <td>8.944</td>\n",
       "      <td>6.852</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,1]</th>\n",
       "      <td>-10.612</td>\n",
       "      <td>8.994</td>\n",
       "      <td>-22.732</td>\n",
       "      <td>0.186</td>\n",
       "      <td>4.492</td>\n",
       "      <td>3.442</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,2]</th>\n",
       "      <td>34.843</td>\n",
       "      <td>20.509</td>\n",
       "      <td>5.877</td>\n",
       "      <td>63.180</td>\n",
       "      <td>10.243</td>\n",
       "      <td>7.847</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.128774e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.weight[2,3]</th>\n",
       "      <td>17.380</td>\n",
       "      <td>9.326</td>\n",
       "      <td>3.456</td>\n",
       "      <td>29.496</td>\n",
       "      <td>4.659</td>\n",
       "      <td>3.569</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.bias[0]</th>\n",
       "      <td>2.910</td>\n",
       "      <td>4.524</td>\n",
       "      <td>-2.588</td>\n",
       "      <td>9.822</td>\n",
       "      <td>2.260</td>\n",
       "      <td>1.731</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.128774e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.bias[1]</th>\n",
       "      <td>1.227</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.899</td>\n",
       "      <td>1.770</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.126</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.128774e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.bias[2]</th>\n",
       "      <td>-4.616</td>\n",
       "      <td>3.849</td>\n",
       "      <td>-9.586</td>\n",
       "      <td>1.212</td>\n",
       "      <td>1.923</td>\n",
       "      <td>1.473</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.573328e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean      sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "1.weight[0,0]  -7.056  20.094 -34.199   22.528     10.037    7.689       4.0   \n",
       "1.weight[0,1]  19.531  16.355   2.257   44.474      8.169    6.258       4.0   \n",
       "1.weight[0,2] -53.708  23.179 -82.892  -18.169     11.578    8.870       4.0   \n",
       "1.weight[0,3] -23.018   9.620 -33.999   -7.621      4.805    3.681       4.0   \n",
       "1.weight[1,0]   6.788   8.489  -6.878   15.597      4.240    3.248       4.0   \n",
       "1.weight[1,1]  -8.613  10.146 -23.316    5.273      5.068    3.883       4.0   \n",
       "1.weight[1,2]  19.112   3.539  14.182   22.795      1.768    1.354       4.0   \n",
       "1.weight[1,3]   5.788   1.740   3.502    8.400      0.869    0.666       4.0   \n",
       "1.weight[2,0]   0.454  17.906 -18.488   29.164      8.944    6.852       4.0   \n",
       "1.weight[2,1] -10.612   8.994 -22.732    0.186      4.492    3.442       4.0   \n",
       "1.weight[2,2]  34.843  20.509   5.877   63.180     10.243    7.847       4.0   \n",
       "1.weight[2,3]  17.380   9.326   3.456   29.496      4.659    3.569       4.0   \n",
       "1.bias[0]       2.910   4.524  -2.588    9.822      2.260    1.731       4.0   \n",
       "1.bias[1]       1.227   0.330   0.899    1.770      0.165    0.126       4.0   \n",
       "1.bias[2]      -4.616   3.849  -9.586    1.212      1.923    1.473       4.0   \n",
       "\n",
       "               ess_tail         r_hat  \n",
       "1.weight[0,0]       4.0  7.128774e+15  \n",
       "1.weight[0,1]       4.0  5.573328e+15  \n",
       "1.weight[0,2]       4.0  7.128774e+15  \n",
       "1.weight[0,3]       4.0  5.573328e+15  \n",
       "1.weight[1,0]       4.0  5.573328e+15  \n",
       "1.weight[1,1]       4.0  5.573328e+15  \n",
       "1.weight[1,2]       4.0  7.128774e+15  \n",
       "1.weight[1,3]       4.0  5.573328e+15  \n",
       "1.weight[2,0]       4.0  5.573328e+15  \n",
       "1.weight[2,1]       4.0  5.573328e+15  \n",
       "1.weight[2,2]       4.0  7.128774e+15  \n",
       "1.weight[2,3]       4.0  5.573328e+15  \n",
       "1.bias[0]           4.0  7.128774e+15  \n",
       "1.bias[1]           4.0  7.128774e+15  \n",
       "1.bias[2]           4.0  5.573328e+15  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 01:19<00:00 Sampling 4 chains, 1,282 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 81 seconds.\n",
      "There were 266 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 272 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 317 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 427 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=5, shape=3)\n",
    "    beta = pm.Normal('beta', mu=0, sd=5, shape=(4,3))\n",
    "    mu = pm.Deterministic('mu', alpha + pm.math.dot(X_train, beta))\n",
    "    theta = tt.nnet.softmax(mu)\n",
    "    y_hat = pm.Categorical('y_hat', p=theta, observed=y_train)\n",
    "    trace_s = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>1.109</td>\n",
       "      <td>4.913</td>\n",
       "      <td>-7.762</td>\n",
       "      <td>10.432</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.160</td>\n",
       "      <td>498.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>4.529</td>\n",
       "      <td>4.465</td>\n",
       "      <td>-2.828</td>\n",
       "      <td>13.372</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.232</td>\n",
       "      <td>208.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>-5.535</td>\n",
       "      <td>4.041</td>\n",
       "      <td>-13.071</td>\n",
       "      <td>2.113</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.078</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0,0]</th>\n",
       "      <td>1.918</td>\n",
       "      <td>3.540</td>\n",
       "      <td>-4.650</td>\n",
       "      <td>8.760</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.099</td>\n",
       "      <td>644.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0,1]</th>\n",
       "      <td>0.876</td>\n",
       "      <td>3.121</td>\n",
       "      <td>-4.801</td>\n",
       "      <td>6.874</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.081</td>\n",
       "      <td>755.0</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[0,2]</th>\n",
       "      <td>-2.448</td>\n",
       "      <td>3.198</td>\n",
       "      <td>-8.691</td>\n",
       "      <td>3.249</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.100</td>\n",
       "      <td>513.0</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1,0]</th>\n",
       "      <td>4.830</td>\n",
       "      <td>4.026</td>\n",
       "      <td>-1.753</td>\n",
       "      <td>12.752</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.159</td>\n",
       "      <td>316.0</td>\n",
       "      <td>1765.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1,1]</th>\n",
       "      <td>-0.782</td>\n",
       "      <td>3.304</td>\n",
       "      <td>-7.066</td>\n",
       "      <td>5.150</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.123</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1,2]</th>\n",
       "      <td>-4.240</td>\n",
       "      <td>3.320</td>\n",
       "      <td>-10.575</td>\n",
       "      <td>2.185</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.079</td>\n",
       "      <td>885.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2,0]</th>\n",
       "      <td>-6.674</td>\n",
       "      <td>3.582</td>\n",
       "      <td>-13.903</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.090</td>\n",
       "      <td>895.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2,1]</th>\n",
       "      <td>0.258</td>\n",
       "      <td>3.148</td>\n",
       "      <td>-5.626</td>\n",
       "      <td>6.390</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2,2]</th>\n",
       "      <td>6.040</td>\n",
       "      <td>3.417</td>\n",
       "      <td>0.431</td>\n",
       "      <td>12.553</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.154</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3,0]</th>\n",
       "      <td>-3.671</td>\n",
       "      <td>4.366</td>\n",
       "      <td>-11.755</td>\n",
       "      <td>4.983</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3,1]</th>\n",
       "      <td>-2.171</td>\n",
       "      <td>3.486</td>\n",
       "      <td>-8.698</td>\n",
       "      <td>4.602</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.084</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3,2]</th>\n",
       "      <td>5.196</td>\n",
       "      <td>3.699</td>\n",
       "      <td>-1.526</td>\n",
       "      <td>12.490</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.094</td>\n",
       "      <td>737.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   1.109  4.913  -7.762   10.432      0.226    0.160     498.0   \n",
       "alpha[1]   4.529  4.465  -2.828   13.372      0.328    0.232     208.0   \n",
       "alpha[2]  -5.535  4.041 -13.071    2.113      0.110    0.078    1300.0   \n",
       "beta[0,0]  1.918  3.540  -4.650    8.760      0.140    0.099     644.0   \n",
       "beta[0,1]  0.876  3.121  -4.801    6.874      0.114    0.081     755.0   \n",
       "beta[0,2] -2.448  3.198  -8.691    3.249      0.141    0.100     513.0   \n",
       "beta[1,0]  4.830  4.026  -1.753   12.752      0.225    0.159     316.0   \n",
       "beta[1,1] -0.782  3.304  -7.066    5.150      0.174    0.123     381.0   \n",
       "beta[1,2] -4.240  3.320 -10.575    2.185      0.112    0.079     885.0   \n",
       "beta[2,0] -6.674  3.582 -13.903   -0.192      0.119    0.090     895.0   \n",
       "beta[2,1]  0.258  3.148  -5.626    6.390      0.093    0.088    1142.0   \n",
       "beta[2,2]  6.040  3.417   0.431   12.553      0.217    0.154     230.0   \n",
       "beta[3,0] -3.671  4.366 -11.755    4.983      0.117    0.083    1343.0   \n",
       "beta[3,1] -2.171  3.486  -8.698    4.602      0.106    0.084    1078.0   \n",
       "beta[3,2]  5.196  3.699  -1.526   12.490      0.133    0.094     737.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]      751.0   1.01  \n",
       "alpha[1]      585.0   1.02  \n",
       "alpha[2]     1394.0   1.02  \n",
       "beta[0,0]    1237.0   1.02  \n",
       "beta[0,1]    1176.0   1.01  \n",
       "beta[0,2]    1551.0   1.01  \n",
       "beta[1,0]    1765.0   1.01  \n",
       "beta[1,1]    1067.0   1.02  \n",
       "beta[1,2]    1181.0   1.01  \n",
       "beta[2,0]     987.0   1.01  \n",
       "beta[2,1]    1281.0   1.02  \n",
       "beta[2,2]    1221.0   1.02  \n",
       "beta[3,0]    2046.0   1.01  \n",
       "beta[3,1]    1430.0   1.01  \n",
       "beta[3,2]    1056.0   1.02  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace_s,var_names=[\"alpha\", \"beta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
